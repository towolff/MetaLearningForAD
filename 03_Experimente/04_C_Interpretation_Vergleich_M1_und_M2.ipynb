{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arrow\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import joblib \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from models.SimpleAutoEncoder import SimpleAutoEncoder\n",
    "\n",
    "from utils.evalUtils import calc_cm_metrics\n",
    "from utils.evalUtils import print_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set configs..\n"
     ]
    }
   ],
   "source": [
    "%run -i ./scripts/setConfigs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/torge/dev/masterthesis_code/02_Experimente/03_Experimente'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set configs..\n",
      "Read the data..\n",
      "Shape of normal data (X_sim): (105216, 17)\n",
      "Shape of anormal data (X_test): (35040, 18)\n",
      "Shape of drifted data (X_drifted): (35040, 18)\n",
      "Shape of drifted anormal data (X_drifted,anormal): (35040, 19)\n",
      "Save label..\n",
      "Shape of anormal data (X_test): (35040, 17)\n",
      "Shape of drifted data (X_drifted): (35040, 17)\n",
      "Shape of drifted anormal data (X_drifted,anormal): (35040, 17)\n",
      "Scale data..\n",
      "Prepare data for PyTorch..\n"
     ]
    }
   ],
   "source": [
    "%run -i ./scripts/EvalPreperations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(drifted_anormal_torch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(exp_data_path, 'experiment'))\n",
    "extension = 'csv'\n",
    "result = glob.glob('*.{}'.format(extension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(exp_data_path, 'experiment', 'fine_tuning', '*.csv')\n",
    "result = glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_results = []\n",
    "for r in result:\n",
    "    if 'tVPII_M2' in r:\n",
    "        real_results.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(real_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tVP2_m2 = pd.read_csv(real_results[0], sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer</th>\n",
       "      <th>fine_tune_classes</th>\n",
       "      <th>name_pretrained_model</th>\n",
       "      <th>k</th>\n",
       "      <th>fine_tune_iterations</th>\n",
       "      <th>lr</th>\n",
       "      <th>model_fn</th>\n",
       "      <th>pretrained_model_fn</th>\n",
       "      <th>logreg_fn</th>\n",
       "      <th>TP_x_test</th>\n",
       "      <th>TN_x_test</th>\n",
       "      <th>FP_x_test</th>\n",
       "      <th>FN_x_test</th>\n",
       "      <th>TP_x_drifted_ano</th>\n",
       "      <th>TN_x_drifted_ano</th>\n",
       "      <th>FP_x_drifted_ano</th>\n",
       "      <th>FN_x_drifted_ano</th>\n",
       "      <th>Accuracy_x_test</th>\n",
       "      <th>Precision_x_test</th>\n",
       "      <th>Specifity_x_test</th>\n",
       "      <th>Sensitivity_x_test</th>\n",
       "      <th>Accuracy_x_drifted_ano</th>\n",
       "      <th>Precision_x_drifted_ano</th>\n",
       "      <th>Specifity_x_drifted_ano</th>\n",
       "      <th>Sensitivity_x_drifted_ano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>M2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>/home/torge/dev/masterthesis_code/02_Experimen...</td>\n",
       "      <td>20200303_LogRegModell.save</td>\n",
       "      <td>/home/torge/dev/masterthesis_code/02_Experimen...</td>\n",
       "      <td>2496</td>\n",
       "      <td>4831</td>\n",
       "      <td>27712</td>\n",
       "      <td>1</td>\n",
       "      <td>2494</td>\n",
       "      <td>4339</td>\n",
       "      <td>28204</td>\n",
       "      <td>3</td>\n",
       "      <td>20.910388</td>\n",
       "      <td>8.262712</td>\n",
       "      <td>65.934216</td>\n",
       "      <td>99.959952</td>\n",
       "      <td>19.500571</td>\n",
       "      <td>8.124308</td>\n",
       "      <td>63.500659</td>\n",
       "      <td>99.879856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  optimizer fine_tune_classes name_pretrained_model  k  fine_tune_iterations  \\\n",
       "0      Adam            [2, 3]                    M2  5                     1   \n",
       "\n",
       "    lr                                           model_fn  \\\n",
       "0  0.1  /home/torge/dev/masterthesis_code/02_Experimen...   \n",
       "\n",
       "          pretrained_model_fn  \\\n",
       "0  20200303_LogRegModell.save   \n",
       "\n",
       "                                           logreg_fn  TP_x_test  TN_x_test  \\\n",
       "0  /home/torge/dev/masterthesis_code/02_Experimen...       2496       4831   \n",
       "\n",
       "   FP_x_test  FN_x_test  TP_x_drifted_ano  TN_x_drifted_ano  FP_x_drifted_ano  \\\n",
       "0      27712          1              2494              4339             28204   \n",
       "\n",
       "   FN_x_drifted_ano  Accuracy_x_test  Precision_x_test  Specifity_x_test  \\\n",
       "0                 3        20.910388          8.262712         65.934216   \n",
       "\n",
       "   Sensitivity_x_test  Accuracy_x_drifted_ano  Precision_x_drifted_ano  \\\n",
       "0           99.959952               19.500571                 8.124308   \n",
       "\n",
       "   Specifity_x_drifted_ano  Sensitivity_x_drifted_ano  \n",
       "0                63.500659                  99.879856  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tVP2_m2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in real_results[1:]:\n",
    "    df = pd.read_csv(file, sep=';')\n",
    "    df_tVP2_m2 = df_tVP2_m2.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tVP2_m2.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer</th>\n",
       "      <th>fine_tune_classes</th>\n",
       "      <th>name_pretrained_model</th>\n",
       "      <th>k</th>\n",
       "      <th>fine_tune_iterations</th>\n",
       "      <th>lr</th>\n",
       "      <th>model_fn</th>\n",
       "      <th>pretrained_model_fn</th>\n",
       "      <th>logreg_fn</th>\n",
       "      <th>TP_x_test</th>\n",
       "      <th>TN_x_test</th>\n",
       "      <th>FP_x_test</th>\n",
       "      <th>FN_x_test</th>\n",
       "      <th>TP_x_drifted_ano</th>\n",
       "      <th>TN_x_drifted_ano</th>\n",
       "      <th>FP_x_drifted_ano</th>\n",
       "      <th>FN_x_drifted_ano</th>\n",
       "      <th>Accuracy_x_test</th>\n",
       "      <th>Precision_x_test</th>\n",
       "      <th>Specifity_x_test</th>\n",
       "      <th>Sensitivity_x_test</th>\n",
       "      <th>Accuracy_x_drifted_ano</th>\n",
       "      <th>Precision_x_drifted_ano</th>\n",
       "      <th>Specifity_x_drifted_ano</th>\n",
       "      <th>Sensitivity_x_drifted_ano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>M2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>/home/torge/dev/masterthesis_code/02_Experimen...</td>\n",
       "      <td>20200303_LogRegModell.save</td>\n",
       "      <td>/home/torge/dev/masterthesis_code/02_Experimen...</td>\n",
       "      <td>2496</td>\n",
       "      <td>4831</td>\n",
       "      <td>27712</td>\n",
       "      <td>1</td>\n",
       "      <td>2494</td>\n",
       "      <td>4339</td>\n",
       "      <td>28204</td>\n",
       "      <td>3</td>\n",
       "      <td>20.910388</td>\n",
       "      <td>8.262712</td>\n",
       "      <td>65.934216</td>\n",
       "      <td>99.959952</td>\n",
       "      <td>19.500571</td>\n",
       "      <td>8.124308</td>\n",
       "      <td>63.500659</td>\n",
       "      <td>99.879856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGD</td>\n",
       "      <td>[1]</td>\n",
       "      <td>M2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>/home/torge/dev/masterthesis_code/02_Experimen...</td>\n",
       "      <td>20200303_LogRegModell.save</td>\n",
       "      <td>/home/torge/dev/masterthesis_code/02_Experimen...</td>\n",
       "      <td>2486</td>\n",
       "      <td>7984</td>\n",
       "      <td>24559</td>\n",
       "      <td>11</td>\n",
       "      <td>2490</td>\n",
       "      <td>7042</td>\n",
       "      <td>25501</td>\n",
       "      <td>7</td>\n",
       "      <td>29.880137</td>\n",
       "      <td>9.192087</td>\n",
       "      <td>76.255969</td>\n",
       "      <td>99.559471</td>\n",
       "      <td>27.203196</td>\n",
       "      <td>8.895716</td>\n",
       "      <td>73.877465</td>\n",
       "      <td>99.719664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adam</td>\n",
       "      <td>[1]</td>\n",
       "      <td>M2</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.10</td>\n",
       "      <td>/home/torge/dev/masterthesis_code/02_Experimen...</td>\n",
       "      <td>20200303_LogRegModell.save</td>\n",
       "      <td>/home/torge/dev/masterthesis_code/02_Experimen...</td>\n",
       "      <td>2494</td>\n",
       "      <td>1005</td>\n",
       "      <td>31538</td>\n",
       "      <td>3</td>\n",
       "      <td>2497</td>\n",
       "      <td>962</td>\n",
       "      <td>31581</td>\n",
       "      <td>0</td>\n",
       "      <td>9.985731</td>\n",
       "      <td>7.328397</td>\n",
       "      <td>28.722492</td>\n",
       "      <td>99.879856</td>\n",
       "      <td>9.871575</td>\n",
       "      <td>7.327308</td>\n",
       "      <td>27.811506</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGD</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>M2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>/home/torge/dev/masterthesis_code/02_Experimen...</td>\n",
       "      <td>20200303_LogRegModell.save</td>\n",
       "      <td>/home/torge/dev/masterthesis_code/02_Experimen...</td>\n",
       "      <td>2400</td>\n",
       "      <td>32543</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>2394</td>\n",
       "      <td>29230</td>\n",
       "      <td>3313</td>\n",
       "      <td>103</td>\n",
       "      <td>99.723174</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>93.131672</td>\n",
       "      <td>96.115338</td>\n",
       "      <td>90.251142</td>\n",
       "      <td>41.948484</td>\n",
       "      <td>92.429800</td>\n",
       "      <td>95.875050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adam</td>\n",
       "      <td>[2]</td>\n",
       "      <td>M2</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>0.10</td>\n",
       "      <td>/home/torge/dev/masterthesis_code/02_Experimen...</td>\n",
       "      <td>20200303_LogRegModell.save</td>\n",
       "      <td>/home/torge/dev/masterthesis_code/02_Experimen...</td>\n",
       "      <td>2485</td>\n",
       "      <td>15295</td>\n",
       "      <td>17248</td>\n",
       "      <td>12</td>\n",
       "      <td>2485</td>\n",
       "      <td>13652</td>\n",
       "      <td>18891</td>\n",
       "      <td>12</td>\n",
       "      <td>50.742009</td>\n",
       "      <td>12.593118</td>\n",
       "      <td>86.023622</td>\n",
       "      <td>99.519423</td>\n",
       "      <td>46.053082</td>\n",
       "      <td>11.625187</td>\n",
       "      <td>84.600607</td>\n",
       "      <td>99.519423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  optimizer fine_tune_classes name_pretrained_model   k  fine_tune_iterations  \\\n",
       "0      Adam            [2, 3]                    M2   5                     1   \n",
       "1       SGD               [1]                    M2   5                     1   \n",
       "2      Adam               [1]                    M2  10                    64   \n",
       "3       SGD            [1, 3]                    M2   5                     1   \n",
       "4      Adam               [2]                    M2  20                    64   \n",
       "\n",
       "     lr                                           model_fn  \\\n",
       "0  0.10  /home/torge/dev/masterthesis_code/02_Experimen...   \n",
       "1  0.01  /home/torge/dev/masterthesis_code/02_Experimen...   \n",
       "2  0.10  /home/torge/dev/masterthesis_code/02_Experimen...   \n",
       "3  0.10  /home/torge/dev/masterthesis_code/02_Experimen...   \n",
       "4  0.10  /home/torge/dev/masterthesis_code/02_Experimen...   \n",
       "\n",
       "          pretrained_model_fn  \\\n",
       "0  20200303_LogRegModell.save   \n",
       "1  20200303_LogRegModell.save   \n",
       "2  20200303_LogRegModell.save   \n",
       "3  20200303_LogRegModell.save   \n",
       "4  20200303_LogRegModell.save   \n",
       "\n",
       "                                           logreg_fn  TP_x_test  TN_x_test  \\\n",
       "0  /home/torge/dev/masterthesis_code/02_Experimen...       2496       4831   \n",
       "1  /home/torge/dev/masterthesis_code/02_Experimen...       2486       7984   \n",
       "2  /home/torge/dev/masterthesis_code/02_Experimen...       2494       1005   \n",
       "3  /home/torge/dev/masterthesis_code/02_Experimen...       2400      32543   \n",
       "4  /home/torge/dev/masterthesis_code/02_Experimen...       2485      15295   \n",
       "\n",
       "   FP_x_test  FN_x_test  TP_x_drifted_ano  TN_x_drifted_ano  FP_x_drifted_ano  \\\n",
       "0      27712          1              2494              4339             28204   \n",
       "1      24559         11              2490              7042             25501   \n",
       "2      31538          3              2497               962             31581   \n",
       "3          0         97              2394             29230              3313   \n",
       "4      17248         12              2485             13652             18891   \n",
       "\n",
       "   FN_x_drifted_ano  Accuracy_x_test  Precision_x_test  Specifity_x_test  \\\n",
       "0                 3        20.910388          8.262712         65.934216   \n",
       "1                 7        29.880137          9.192087         76.255969   \n",
       "2                 0         9.985731          7.328397         28.722492   \n",
       "3               103        99.723174        100.000000         93.131672   \n",
       "4                12        50.742009         12.593118         86.023622   \n",
       "\n",
       "   Sensitivity_x_test  Accuracy_x_drifted_ano  Precision_x_drifted_ano  \\\n",
       "0           99.959952               19.500571                 8.124308   \n",
       "1           99.559471               27.203196                 8.895716   \n",
       "2           99.879856                9.871575                 7.327308   \n",
       "3           96.115338               90.251142                41.948484   \n",
       "4           99.519423               46.053082                11.625187   \n",
       "\n",
       "   Specifity_x_drifted_ano  Sensitivity_x_drifted_ano  \n",
       "0                63.500659                  99.879856  \n",
       "1                73.877465                  99.719664  \n",
       "2                27.811506                 100.000000  \n",
       "3                92.429800                  95.875050  \n",
       "4                84.600607                  99.519423  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tVP2_m2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_tVP2_m2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_tVP2_m2['ano_labels'] = s_ano_labels_drifted_ano\n",
    "df_results_tVP2_m2.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 1 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 2 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 3 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 4 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 5 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 6 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 7 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 8 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 9 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 10 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 11 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 12 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 13 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 14 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 15 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 16 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 17 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 18 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 19 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 20 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 21 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 22 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 23 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 24 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 25 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 26 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 27 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 28 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 29 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 30 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 31 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 32 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 33 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 34 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 35 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 36 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 37 of 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torge/anaconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "for i, row in df_tVP2_m2.iterrows():\n",
    "    print('Current Iteration: {} of {}'.format(i+1, len(df_tVP2_m2)))\n",
    "    model = None\n",
    "    model = SimpleAutoEncoder(num_inputs=17, val_lambda=42)\n",
    "    logreg = None\n",
    "    \n",
    "    model_fn = row['model_fn']\n",
    "    logreg_fn = row['logreg_fn']\n",
    "    \n",
    "    logreg = joblib.load(logreg_fn)\n",
    "    model.load_state_dict(torch.load(model_fn))\n",
    "    \n",
    "    losses = []\n",
    "    for val in drifted_anormal_torch_tensor:\n",
    "        loss = model.calc_reconstruction_error(val)\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    s_losses_anormal = pd.Series(losses)\n",
    "    \n",
    "    X = s_losses_anormal.to_numpy()\n",
    "    X = X.reshape(-1, 1)\n",
    "    \n",
    "    predictions = []\n",
    "    for val in X:\n",
    "        val = val.reshape(1,-1)\n",
    "        pred = logreg.predict(val)\n",
    "        predictions.append(pred[0])\n",
    "\n",
    "    col_name = 'preds_model_{}'.format(i)\n",
    "    \n",
    "    df_results_tVP2_m2[col_name] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '{}_predictions_models_m2_phase_2_on_x_drifted_ano.csv'.format(arrow.now().format('YYYYMMDD'))\n",
    "full_fn = '/home/torge/dev/masterthesis_code/02_Experimente/03_Experimente/exp_data/evaluation/{}'.format(file_name)\n",
    "df_results_tVP2_m2.to_csv(full_fn, sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_results_tVP2_m2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35040"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_results_tVP2_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano_labels</th>\n",
       "      <th>preds_model_0</th>\n",
       "      <th>preds_model_1</th>\n",
       "      <th>preds_model_2</th>\n",
       "      <th>preds_model_3</th>\n",
       "      <th>preds_model_4</th>\n",
       "      <th>preds_model_5</th>\n",
       "      <th>preds_model_6</th>\n",
       "      <th>preds_model_7</th>\n",
       "      <th>preds_model_8</th>\n",
       "      <th>preds_model_9</th>\n",
       "      <th>preds_model_10</th>\n",
       "      <th>preds_model_11</th>\n",
       "      <th>preds_model_12</th>\n",
       "      <th>preds_model_13</th>\n",
       "      <th>preds_model_14</th>\n",
       "      <th>preds_model_15</th>\n",
       "      <th>preds_model_16</th>\n",
       "      <th>preds_model_17</th>\n",
       "      <th>preds_model_18</th>\n",
       "      <th>preds_model_19</th>\n",
       "      <th>preds_model_20</th>\n",
       "      <th>preds_model_21</th>\n",
       "      <th>preds_model_22</th>\n",
       "      <th>preds_model_23</th>\n",
       "      <th>preds_model_24</th>\n",
       "      <th>preds_model_25</th>\n",
       "      <th>preds_model_26</th>\n",
       "      <th>preds_model_27</th>\n",
       "      <th>preds_model_28</th>\n",
       "      <th>preds_model_29</th>\n",
       "      <th>preds_model_30</th>\n",
       "      <th>preds_model_31</th>\n",
       "      <th>preds_model_32</th>\n",
       "      <th>preds_model_33</th>\n",
       "      <th>preds_model_34</th>\n",
       "      <th>preds_model_35</th>\n",
       "      <th>preds_model_36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "      <td>35040.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.143208</td>\n",
       "      <td>0.876084</td>\n",
       "      <td>0.798830</td>\n",
       "      <td>0.972546</td>\n",
       "      <td>0.162871</td>\n",
       "      <td>0.610046</td>\n",
       "      <td>0.798744</td>\n",
       "      <td>0.764840</td>\n",
       "      <td>0.723059</td>\n",
       "      <td>0.820548</td>\n",
       "      <td>0.758676</td>\n",
       "      <td>0.164412</td>\n",
       "      <td>0.757449</td>\n",
       "      <td>0.801341</td>\n",
       "      <td>0.760873</td>\n",
       "      <td>0.727340</td>\n",
       "      <td>0.707648</td>\n",
       "      <td>0.819349</td>\n",
       "      <td>0.909132</td>\n",
       "      <td>0.900342</td>\n",
       "      <td>0.162529</td>\n",
       "      <td>0.667608</td>\n",
       "      <td>0.789384</td>\n",
       "      <td>0.720120</td>\n",
       "      <td>0.970862</td>\n",
       "      <td>0.730736</td>\n",
       "      <td>0.163385</td>\n",
       "      <td>0.163413</td>\n",
       "      <td>0.730736</td>\n",
       "      <td>0.164269</td>\n",
       "      <td>0.799458</td>\n",
       "      <td>0.185788</td>\n",
       "      <td>0.757877</td>\n",
       "      <td>0.184047</td>\n",
       "      <td>0.725685</td>\n",
       "      <td>0.733647</td>\n",
       "      <td>0.164269</td>\n",
       "      <td>0.900400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.518759</td>\n",
       "      <td>0.329490</td>\n",
       "      <td>0.400881</td>\n",
       "      <td>0.163406</td>\n",
       "      <td>0.369253</td>\n",
       "      <td>0.487747</td>\n",
       "      <td>0.400944</td>\n",
       "      <td>0.424105</td>\n",
       "      <td>0.447493</td>\n",
       "      <td>0.383736</td>\n",
       "      <td>0.427893</td>\n",
       "      <td>0.370654</td>\n",
       "      <td>0.428632</td>\n",
       "      <td>0.398996</td>\n",
       "      <td>0.426556</td>\n",
       "      <td>0.445334</td>\n",
       "      <td>0.454849</td>\n",
       "      <td>0.384734</td>\n",
       "      <td>0.287425</td>\n",
       "      <td>0.299547</td>\n",
       "      <td>0.368940</td>\n",
       "      <td>0.471077</td>\n",
       "      <td>0.407752</td>\n",
       "      <td>0.448947</td>\n",
       "      <td>0.168196</td>\n",
       "      <td>0.443584</td>\n",
       "      <td>0.369722</td>\n",
       "      <td>0.369748</td>\n",
       "      <td>0.443584</td>\n",
       "      <td>0.370525</td>\n",
       "      <td>0.400412</td>\n",
       "      <td>0.388941</td>\n",
       "      <td>0.428375</td>\n",
       "      <td>0.387528</td>\n",
       "      <td>0.446175</td>\n",
       "      <td>0.442057</td>\n",
       "      <td>0.370525</td>\n",
       "      <td>0.299471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ano_labels  preds_model_0  preds_model_1  preds_model_2  \\\n",
       "count  35040.000000   35040.000000   35040.000000   35040.000000   \n",
       "mean       0.143208       0.876084       0.798830       0.972546   \n",
       "std        0.518759       0.329490       0.400881       0.163406   \n",
       "min        0.000000       0.000000       0.000000       0.000000   \n",
       "25%        0.000000       1.000000       1.000000       1.000000   \n",
       "50%        0.000000       1.000000       1.000000       1.000000   \n",
       "75%        0.000000       1.000000       1.000000       1.000000   \n",
       "max        3.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       preds_model_3  preds_model_4  preds_model_5  preds_model_6  \\\n",
       "count   35040.000000   35040.000000   35040.000000   35040.000000   \n",
       "mean        0.162871       0.610046       0.798744       0.764840   \n",
       "std         0.369253       0.487747       0.400944       0.424105   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       1.000000       1.000000   \n",
       "50%         0.000000       1.000000       1.000000       1.000000   \n",
       "75%         0.000000       1.000000       1.000000       1.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       preds_model_7  preds_model_8  preds_model_9  preds_model_10  \\\n",
       "count   35040.000000   35040.000000   35040.000000    35040.000000   \n",
       "mean        0.723059       0.820548       0.758676        0.164412   \n",
       "std         0.447493       0.383736       0.427893        0.370654   \n",
       "min         0.000000       0.000000       0.000000        0.000000   \n",
       "25%         0.000000       1.000000       1.000000        0.000000   \n",
       "50%         1.000000       1.000000       1.000000        0.000000   \n",
       "75%         1.000000       1.000000       1.000000        0.000000   \n",
       "max         1.000000       1.000000       1.000000        1.000000   \n",
       "\n",
       "       preds_model_11  preds_model_12  preds_model_13  preds_model_14  \\\n",
       "count    35040.000000    35040.000000    35040.000000    35040.000000   \n",
       "mean         0.757449        0.801341        0.760873        0.727340   \n",
       "std          0.428632        0.398996        0.426556        0.445334   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          1.000000        1.000000        1.000000        0.000000   \n",
       "50%          1.000000        1.000000        1.000000        1.000000   \n",
       "75%          1.000000        1.000000        1.000000        1.000000   \n",
       "max          1.000000        1.000000        1.000000        1.000000   \n",
       "\n",
       "       preds_model_15  preds_model_16  preds_model_17  preds_model_18  \\\n",
       "count    35040.000000    35040.000000    35040.000000    35040.000000   \n",
       "mean         0.707648        0.819349        0.909132        0.900342   \n",
       "std          0.454849        0.384734        0.287425        0.299547   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          0.000000        1.000000        1.000000        1.000000   \n",
       "50%          1.000000        1.000000        1.000000        1.000000   \n",
       "75%          1.000000        1.000000        1.000000        1.000000   \n",
       "max          1.000000        1.000000        1.000000        1.000000   \n",
       "\n",
       "       preds_model_19  preds_model_20  preds_model_21  preds_model_22  \\\n",
       "count    35040.000000    35040.000000    35040.000000    35040.000000   \n",
       "mean         0.162529        0.667608        0.789384        0.720120   \n",
       "std          0.368940        0.471077        0.407752        0.448947   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          0.000000        0.000000        1.000000        0.000000   \n",
       "50%          0.000000        1.000000        1.000000        1.000000   \n",
       "75%          0.000000        1.000000        1.000000        1.000000   \n",
       "max          1.000000        1.000000        1.000000        1.000000   \n",
       "\n",
       "       preds_model_23  preds_model_24  preds_model_25  preds_model_26  \\\n",
       "count    35040.000000    35040.000000    35040.000000    35040.000000   \n",
       "mean         0.970862        0.730736        0.163385        0.163413   \n",
       "std          0.168196        0.443584        0.369722        0.369748   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          1.000000        0.000000        0.000000        0.000000   \n",
       "50%          1.000000        1.000000        0.000000        0.000000   \n",
       "75%          1.000000        1.000000        0.000000        0.000000   \n",
       "max          1.000000        1.000000        1.000000        1.000000   \n",
       "\n",
       "       preds_model_27  preds_model_28  preds_model_29  preds_model_30  \\\n",
       "count    35040.000000    35040.000000    35040.000000    35040.000000   \n",
       "mean         0.730736        0.164269        0.799458        0.185788   \n",
       "std          0.443584        0.370525        0.400412        0.388941   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          0.000000        0.000000        1.000000        0.000000   \n",
       "50%          1.000000        0.000000        1.000000        0.000000   \n",
       "75%          1.000000        0.000000        1.000000        0.000000   \n",
       "max          1.000000        1.000000        1.000000        1.000000   \n",
       "\n",
       "       preds_model_31  preds_model_32  preds_model_33  preds_model_34  \\\n",
       "count    35040.000000    35040.000000    35040.000000    35040.000000   \n",
       "mean         0.757877        0.184047        0.725685        0.733647   \n",
       "std          0.428375        0.387528        0.446175        0.442057   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          1.000000        0.000000        0.000000        0.000000   \n",
       "50%          1.000000        0.000000        1.000000        1.000000   \n",
       "75%          1.000000        0.000000        1.000000        1.000000   \n",
       "max          1.000000        1.000000        1.000000        1.000000   \n",
       "\n",
       "       preds_model_35  preds_model_36  \n",
       "count    35040.000000    35040.000000  \n",
       "mean         0.164269        0.900400  \n",
       "std          0.370525        0.299471  \n",
       "min          0.000000        0.000000  \n",
       "25%          0.000000        1.000000  \n",
       "50%          0.000000        1.000000  \n",
       "75%          0.000000        1.000000  \n",
       "max          1.000000        1.000000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_tVP2_m2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma_modells",
   "language": "python",
   "name": "ma_modells"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
