{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning Phase als Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arrow\n",
    "import learn2learn as l2l\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from torch.nn import Module, Linear, Sequential, ReLU\n",
    "from torch.nn.functional import mse_loss\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.evalUtils import print_confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set configs..\n"
     ]
    }
   ],
   "source": [
    "%run -i ./scripts/setConfigs.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Models\n",
    "### Meta-AE M_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Meta Model AE..\n",
      "/Users/torge/Development/master/masterthesis_code/02_Experimente/MetaLearning/models/model_bib/20200319_firstMetaModel.pt\n",
      "SimpleAutoEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=17, out_features=12, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=12, out_features=8, bias=True)\n",
      "    (3): Tanh()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=8, out_features=12, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=12, out_features=17, bias=True)\n",
      "    (3): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "%run -i ./scripts/ReadSimpleAE_MetaModel.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load trained LogReg..\n",
      "LogisticRegression(C=1.0, class_weight={1: 2.0}, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/torge/miniconda3/envs/ma_modells/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "%run -i ./scripts/ReadLogReg_Meta.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train data: (105216, 17)\n"
     ]
    }
   ],
   "source": [
    "data_fn = os.path.join(data_path, 'simulation_data_y_2020_2021_reduced.h5')\n",
    "df_data_train = pd.read_hdf(data_fn, key='df')\n",
    "print('Shape of X_train data: {}'.format(df_data_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test data: (35040, 18)\n"
     ]
    }
   ],
   "source": [
    "data_fn = os.path.join(data_path, 'anomalous_data_y_2022_reduced.h5')\n",
    "df_data_anormal = pd.read_hdf(data_fn, key='df')\n",
    "print('Shape of X_test data: {}'.format(df_data_anormal.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test data: (35040, 17)\n"
     ]
    }
   ],
   "source": [
    "s_labels = df_data_anormal['label']\n",
    "df_data_anormal.drop('label', axis=1, inplace=True)\n",
    "print('Shape of X_test data: {}'.format(df_data_anormal.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_drifted data: (35040, 18)\n"
     ]
    }
   ],
   "source": [
    "data_fn = os.path.join(data_path, 'drifted_data_y_2023_reduced_more_cos_phi.h5')\n",
    "df_data_drifted = pd.read_hdf(data_fn, key='df')\n",
    "print('Shape of X_drifted data: {}'.format(df_data_drifted.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_drifted data: (35040, 17)\n"
     ]
    }
   ],
   "source": [
    "s_drift_labels_x_drifted = df_data_drifted['drift_labels']\n",
    "df_data_drifted.drop('drift_labels', axis=1, inplace=True)\n",
    "print('Shape of X_drifted data: {}'.format(df_data_drifted.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_drifted,ano data: (35040, 19)\n"
     ]
    }
   ],
   "source": [
    "data_fn = os.path.join(data_path, 'anomalous_drifted_data_y_2023_reduced_more_cos_phi.h5')\n",
    "df_data_drifted_ano = pd.read_hdf(data_fn, key='df')\n",
    "print('Shape of X_drifted,ano data: {}'.format(df_data_drifted_ano.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_drifted_ano_drift_labels = df_data_drifted_ano['drift_labels']\n",
    "s_drifted_ano_ano_labels = df_data_drifted_ano['anomaly_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_drifted,ano data: (35040, 17)\n"
     ]
    }
   ],
   "source": [
    "df_data_drifted_ano.drop(['drift_labels', 'anomaly_labels'], axis=1, inplace=True)\n",
    "print('Shape of X_drifted,ano data: {}'.format(df_data_drifted_ano.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale data..\n"
     ]
    }
   ],
   "source": [
    "print('Scale data..')\n",
    "scaler_train = MinMaxScaler((-1,1))\n",
    "scaler_train = scaler_train.fit(df_data_train)\n",
    "scaled_train = scaler_train.transform(df_data_train.to_numpy())\n",
    "scaled_anormal = scaler_train.transform(df_data_anormal.to_numpy())\n",
    "scaled_drifted = scaler_train.transform(df_data_drifted.to_numpy())\n",
    "scaled_drifted_ano = scaler_train.transform(df_data_drifted_ano.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build tensor from numpy\n",
    "anormal_torch_tensor = torch.from_numpy(scaled_anormal).type(torch.FloatTensor)\n",
    "anormal_drifted_torch_tensor = torch.from_numpy(scaled_drifted_ano).type(torch.FloatTensor)\n",
    "drifted_torch_tensor_X = torch.from_numpy(scaled_drifted).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build tensor from numpy\n",
    "drifted_torch_tensor_y = torch.from_numpy(s_drift_labels_x_drifted.to_numpy().reshape(len(s_drift_labels_x_drifted),1)).type(torch.FloatTensor)\n",
    "drifted_anormal_torch_tensor_y = torch.from_numpy(s_drifted_ano_drift_labels.to_numpy().reshape(len(s_drifted_ano_drift_labels),1)).type(torch.FloatTensor)\n",
    "drifted_anormal_torch_tensor_anos_y = torch.from_numpy(s_drifted_ano_ano_labels.to_numpy().reshape(len(s_drifted_ano_ano_labels),1)).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pytorch dataset from tensor\n",
    "drifted_dataset = TensorDataset(drifted_torch_tensor_X, drifted_torch_tensor_y)\n",
    "drifted_anormal_dataset = torch.utils.data.TensorDataset(anormal_drifted_torch_tensor, drifted_anormal_torch_tensor_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(meta_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Experiments.FineTuneExperiment import FineTuneExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITERATIONS = 1000\n",
    "NUM_EXPERIMENTS = 100\n",
    "K = 5\n",
    "FILTERED_CLASSES = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Tuner: 100%|██████████| 100/100 [31:52<00:00, 19.13s/it] \n"
     ]
    }
   ],
   "source": [
    "exp = FineTuneExperiment(num_fine_tuner=NUM_EXPERIMENTS, model=meta_model, fine_tune_data=drifted_dataset,\n",
    "                 eval_data=drifted_anormal_dataset, k=K, fine_tune_iterations=NUM_ITERATIONS,\n",
    "                 optimizer=optimizer, fine_tune_classes=FILTERED_CLASSES, \n",
    "                 classifier=clf_meta, eval_label=drifted_anormal_torch_tensor_anos_y)\n",
    "\n",
    "exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++\n",
      "Average Accuracy: 85.53872716892538\n",
      "Average Precision: 33.50977459533905\n",
      "Average Specifity: 92.06774561534051\n",
      "Average Sensitivity: 94.96796155348427\n",
      "++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "exp.avg_kpis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma_modells",
   "language": "python",
   "name": "ma_modells"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
